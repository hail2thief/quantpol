---
title: "Modeling II"
subtitle: "The Scientific Study of Politics"  
author: 
  - "Juan Tellez"
date: '`r Sys.Date()`'
output:
  xaringan::moon_reader:
    lib_dir: "libs"
    css: ["default", "css/my-theme.css", "css/halloween.css"]
    seal: false
    nature:
      highlightStyle: github
      highlightLanguage: ["r"]
      highlightLines: true
      highlightSpans: true
      countIncrementalSlides: false
      ratio: "16:9"
      navigation:
        scroll: false
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.width=9, 
  fig.height=3.5, 
  fig.retina=3,
  out.width = "100%",
  cache = FALSE,
  echo = FALSE,
  message = FALSE, 
  warning = FALSE,
  hiline = TRUE
)
```



```{r packages}
library(tidyverse)
library(socviz)
library(fivethirtyeight)
library(patchwork)
library(gapminder)
library(broom)
library(equatiomatic)
library(juanr)

# dubois colors
red = "#dc354a"
yellow = "#ecb025"
blue = "#213772"



# theme
theme_nice = function() {
  theme_minimal(base_family = "Fira Sans Condensed", base_size = 14) +
    theme(panel.grid.minor = element_blank(),
          plot.background = element_rect(fill = "white", color = NA),
          plot.title = element_text(face = "bold"),
          axis.title = element_text(face = "bold"),
          strip.text = element_text(face = "bold"),
          strip.background = element_rect(fill = "grey80", color = NA),
          legend.title = element_text(face = "bold"), 
          plot.subtitle = element_text(hjust = .5, face = "italic"))
}
theme_set(theme_nice())


# set seed
set.seed(1990)

```



class: left, middle
background-image: url("images/dubois-spiral-2.png")
background-position: right
background-size: contain

# `r rmarkdown::metadata$title`

### *`r rmarkdown::metadata$subtitle`*

### Professor `r rmarkdown::metadata$author` 

#### University of California, Davis

---


class: center
.large[
# Today's agenda
]

--
.box-1.large.sp-after[Modeling with `lm`]

--
.box-2.large.sp-after[Modeling with numbers]

--
.box-3.large.sp-after[Modeling with categories]

---


# The big picture: modeling

.pull-left[
What we want out of our model:

Does TV news make people more energized to vote? Or does it turn them off from politics? 

**How much** does an additional hour of TV increase (or decrease) the likelihood that someone votes? 

**What level** of Y (voter turnout) should we expect for a given level of X (exposure to the news)? 

]

.pull-right[
```{r,out.width="70%"}
knitr::include_graphics("images/big-picture.jpeg")
```

]


---



class: center, middle, inverse
# Modeling with lm
---


# How does car weight impact fuel efficiency?

Remember, we want the underlying model from this line

$mpg = \beta_0 + \beta1 \times weight$


```{r, out.width="80%"}
ggplot(mtcars, aes(x = wt, y = mpg)) + 
  geom_point(color = blue, alpha = .8) + 
  theme_fancy + labs(x = "Weight (1000 lbs)", 
                     y = "Miles/gallon (mpg)") + 
  geom_smooth(method = "lm", fullrange = TRUE)
```

---


# Modeling in R

--

We can use the `lm()` function to create models in R, using this formula:

> lm(Y ~ X1, data = DATA)


--

```{r,echo = TRUE}
weight_model = lm(mpg ~ wt, data = mtcars) #<<
```

Notice! Saved as a model object

---


# Extract the model

We can extract the model equation with `tidy()`, from the `broom` package

```{r,echo = TRUE}
tidy(weight_model)
```

---

# Making sense of the table


$mpg = \beta_0 + \beta_1 \times weight$

```{r,echo = TRUE}
tidy(weight_model)
```

--

The `estimate` column gives us $\beta_0$ (intercept) and $\beta_1$ (slope for weight)

--

Note! We only care about the first two columns of `tidy()` so far

---


# Extract the model


$mpg = \beta_0 + \beta_1 \times weight$


```{r}
tidy(weight_model) %>%
  knitr::kable(digits = 2)
```

--

The intercept ( $\beta_0$ ) = 37.29

--

The slope ( $\beta_1$ ) = -5.3

--

The model: $mpg = 37.29 + -5.3 \times weight$

---

class: center, middle, inverse
# Modeling with numbers
---


# Back to the cars

The model: $mpg = 37.29 + -5.3 \times weight$

How do we interpret the slope on *weight*? 

```{r, out.width="80%"}
ggplot(mtcars, aes(x = wt, y = mpg)) + 
  geom_point(color = blue, alpha = .8) + 
  theme_fancy + labs(x = "Weight (1000 lbs)", 
                     y = "Miles/gallon (mpg)") + 
  geom_smooth(method = "lm", fullrange = TRUE)
```


---


# Interpretation: continuous variables


.pull-left[
As you turn the dimmer (*treatment variable*) the light (*outcome variable*) changes

Turn the dimmer up, the light increases by SLOPE amount

Turn the dimmer down, the light decreases by SLOPE amount

The change is **gradual**
]

.pull-right[
```{r}
knitr::include_graphics("images/dimmer.jpeg")
```
]

---

# Interpretation: the slope

$mpg = 37.2 + \color{red}{-5.3} \times weight$



```{r}
tidy(weight_model) %>%
  knitr::kable(digits = 2)
```


--

**General**: for every *unit increase* in X (weight), Y (mpg) changes by $\color{red}{5.3}$ *units*

--

**Specific**: for every *ton of weight* you add to a car, you lose $\color{red}{5.3}$ *miles per gallon* of fuel efficiency


---


# Interpretation: the intercept


$mpg = \color{red}{37.2} + -5.3 \times weight$

--

Remember that the Y-intercept is the *value of Y when X = 0*


$$
\begin{aligned}
Y = 6 + 2x \\
X = 0 \\
Y = 6 + 2 \times 0 \\
Y = 6
\end{aligned}
$$
---


# Interpretation: the intercept


Take the formula: $mpg = \color{red}{37.2} + -5.3 \times weight$

--

Set X (weight) equal to 0 $\rightarrow$ $\color{red}{37.2} + (-5.3 \times 0) = \color{red}{37.2}$

--


**General**: The estimated value of Y (mpg), when X (weight) equals zero, is $\color{red}{37.2}$ units

--

**Specific**: The estimated fuel efficiency for a car that weighs *0 tons* is $\color{red}{37.2}$ miles per gallon

---


# Spot the intercept

$mpg = 37.29 + -5.3 \times weight$

```{r, out.width="80%"}
ggplot(mtcars, aes(x = wt, y = mpg)) +
  coord_cartesian(xlim = c(0, 7), ylim = c(0, 40)) +
  geom_point(color = blue, alpha = .8) +
  theme_fancy + labs(x = "Weight (1000 lbs)",
                     y = "Miles/gallon (mpg)") +
  geom_smooth(method = "lm", fullrange = TRUE) +
  geom_abline(data = NULL, intercept = coef(weight_model)[1],
              slope = coef(weight_model)[2], lty = 2, color = "black")
```

We can confirm we're not crazy if we zoom out

---


# Nonsense intercepts


$mpg = 37.2 + -5.3 \times weight$


Interpretation of the intercept:

> The average fuel efficiency for a car that weighs nothing is 37.2 miles per gallon

--

Note that this is **nonsense**: a car cannot weigh zero tons

--

You will run into this often: don't let it confuse you!

--

the intercept will rarely be useful on its own; But we **need** it to draw the line!


---


# Another example: gapminder


Say we want to estimate the relationship between **GDP per capita** and **life expectancy**


```{r}
ggplot(gapminder, aes(x = gdpPercap, y = lifeExp)) +
  geom_point(color = red, alpha = .8)
```

---


# The model

We fit the model using `lm()`

```{r,echo = TRUE}
wealth_mod = lm(lifeExp ~ gdpPercap, data = gapminder)
```

--


We extract the coefficient estimates using `tidy()`

```{r, echo = TRUE}
tidy(wealth_mod)
```



---

# Interpreting the model

$LifeExp = \beta_0 + \beta1 \times gdpPercap$

```{r}
tidy(wealth_mod)
```

--

$\beta_1$, the slope = for every additional dollar of GDP, a country's life expectancy rises by .0007 years

--

$\beta_0$, the intercept = the average life expectancy for a country with no economic activity (GDP = 0) is 54 years

---


# The scale of the coefficients


$LifeExp = 54 + .0007 \times gdpPercap$


Slope: for every **dollar** increase in GDP, life expectancy increases by 0.0007 years

--

Tiny! Does this mean a country's wealth has little to do with their health?

--

No! It is a problem with the **scale** that GDP is in

--

one dollar differences in GDP are tiny, meaningless; GDP changes by much more from year to year


---

# Variable scales


We can rescale GDP so that it's in 10s of thousands of dollars:

```{r,echo = TRUE}
gapminder = gapminder %>%
  mutate(gdp_10k = gdpPercap/10000)
```

---


# Variable scales

Note the variable is the same; only thing that has changed is the scale!

```{r}
gapminder %>%
  select(`GDP (in dollars)` = gdpPercap, 
         `GDP (in tens of thousands of dollars)` = gdp_10k) %>%
  pivot_longer(everything()) %>%
  ggplot(aes(x = value)) +
  geom_histogram(fill = red, alpha = .8, color = "white", bins = 30) +
  facet_wrap(vars(name), scales = "free") +
  theme_fancy + scale_x_continuous(labels = scales::dollar)
```

---


# Re-fit the model



```{r,echo = TRUE}
wealth_mod_10k = lm(lifeExp ~ gdp_10k, data = gapminder)
tidy(wealth_mod_10k)
```

--

for every additional $10,000 of GDP, a country gains about 7 years

--

Mind your *scales*: if a coefficient is tiny, ask yourself if the scale makes sense


---

# ðŸš¨ ðŸš¢ Why do some countries export more than others? ðŸš¢ ðŸš¨

--

1. For a year of your choosing, make a scatterplot of imports (x-axis) and exports (y-axis) with a trend-line. Add labels so you can see which countries are the outliers. 

--

2. Estimate a model that models how much a country exports, using a treatment variable of your choosing. Interpret the model output. 



```{r}
countdown::countdown(minutes = 5L)
```


---



class: center, middle, inverse
# Regression with categorical variables
---


# Categorical variables


We can also use categorical variables in our models

--

The simplest categorical variable is a *binary variable*: Men vs. women, young vs. old, has a policy in place (vs. not), TRUE/FALSE

--

Dummy variables (1/0) are a common type of binary variable

--

Let's say I wanted to look at the relationship between a country's organ donation policy and its organ donation rate


---


# Organ data

```{r}
set.seed(1990)
organdata %>%
  sample_n(10) %>%
  select(country, year, opt, donors) %>%
  knitr::kable()
```

---


# Binary variables in models


I can include the binary variable in a regression model:

```{r, echo = TRUE}
donor_mod = lm(donors ~ opt, data = organdata)
```

--

And look at the output:

```{r}
tidy(donor_mod)
```

---

# How to interpret categorical variables?


.pull-left[

Turn the light on (`opt` goes from "In" to "Out"), the light *increases* by SLOPE

Turn the light off (`opt` goes from "Out" to "In"), the light *decreases* by SLOPE

The change is **instant**
]

.pull-right[
```{r}
knitr::include_graphics("images/switch.jpeg")
```
]

---


# Modeling binary variables


With a binary variable, R will pick one level of the variable to make the .shout[reference category]

--

The other level is the **change**, or **offset**, from that reference


---


# Interpreting categories

.small[
$\operatorname{\widehat{donors}} = 14.31 + 5.5(\operatorname{opt}_{\operatorname{Out}})$
]

```{r}
tidy(donor_mod)
```

.small[
Slope: Country-years where people have to OPT OUT of donating their organs have, on average, 5.5 more donations per million residents than country-years where people have to OPT IN

]

--

.small[
Intercept (set `opt` = "In"): Country-years where people have to OPT IN to organ donation have, on average, 14.3 donations per million residents
]


---

# Categorical variables


The difference between the .red[red line] and the .blue[blue line] is `r round(lines$mean[2] - lines$mean[1], 2)`

```{r}
lines = organdata %>% 
  drop_na(opt) %>% 
  group_by(opt) %>% 
  summarise(mean = mean(donors, na.rm = TRUE))

ggplot(drop_na(organdata, opt), aes(x = opt, y = donors, 
                                    color = opt)) + 
  ggbeeswarm::geom_beeswarm(alpha = .8) + 
  geom_segment(data = lines, aes(x = c(.5, 2.5), y = mean, xend = 1.5, 
                                 yend = mean, color = opt), 
               size = 2) + 
  scale_color_manual(values = c(blue, red)) + 
  theme(legend.position = "none") + 
  labs(x = "Organ donation: opt in or out?", 
       y = "Average donation rate\n(donors per million residents)")
```

---


# What if I have more than one dummy?


Say I go back and create a dummy for each continent:


```{r, echo = TRUE}
gap_dummies = gapminder %>%
  mutate(is_africa = continent == "Africa",
         is_europe = continent == "Europe",
         is_asia = continent == "Asia",
         is_oceania = continent == "Oceania",
         is_americas = continent == "Americas")
```


---

# Multiple dummies


I can include more than one dummy in a regression:

```{r, echo = TRUE}
dummy_mod2 = lm(lifeExp ~ is_americas + is_europe, data = gap_dummies)

tidy(dummy_mod2)
```

---


# Multiple dummies

.small[
$\operatorname{\widehat{lifeExp}} = 53.7 + 10.96(\operatorname{is\_americas}) + 18.2(\operatorname{is\_europe})$
]

--

.small[
```{r}
tidy(dummy_mod2)
```
]

--

.small[
`is_americas` = countries in the Americas have, on average, 11 years more of life expectancy than countries not **in the Americas or Europe** (so: Asia, Africa, Oceania)

`is_europe` = countries in Europe have, on average, 18 years more of life expectancy than countries not **in the Americas or Europe** (so: Asia, Africa, Oceania)

`intercept` = set `is_americas` and `is_europe` equal to 0. Countries in Africa, Oceania, and Asia (not in Americas or Europe) have an average life expectancy of 53.7 years
]

---

# One last time


```{r, echo = TRUE}
dummy_mod3 = lm(lifeExp ~ is_americas + is_europe + is_asia + is_oceania, 
                data = gap_dummies)

tidy(dummy_mod3)
```

---


# One last time

.small[
```{r}
tidy(dummy_mod3)
```

]

--

.small[
* `is_americas` = countries in the Americas have, on average, 15 years more of life expectancy than countries **not in the Americas or Europe or Asia or Oceania** (so: Africa)

* `is_europe` = countries in Europe have, on average, 23 years more of life expectancy than countries **not in the Americas or Europe or Asia or Oceania** (so: Africa)

* `is_asia` = countries in Asia have, on average, 11 years more of life expectancy than countries **not in the Americas or Europe or Asia or Oceania** (so: Africa)

]

---

# One last time

.small[
$$
\begin{aligned}
\operatorname{\widehat{lifeExp}} &= 48.87 + 15.79(\operatorname{is\_americas}) + 23.04(\operatorname{is\_europe}) + 11.2(\operatorname{is\_asia})\ + \\
&\quad 25.46(\operatorname{is\_oceania})
\end{aligned}
$$
]


.small[
```{r}
tidy(dummy_mod3)

```
]

--

.small[

* `is_oceania` = countries in Oceania have, on average, 25 years more of life expectancy than countries **not in the Americas or Europe or Asia or Oceania** (Africa)

* `intercept` = countries in Africa (**not in Americas or Europe or Asia or Oceania**) have an average life expectancy of 48.9 years
]


---

# The pattern

Notice how the coefficient in each dummy is how much *higher* or *lower* the continent is, relative to the intercept (every other continent)

--

As you add more continent dummies, the coefficient changes

--

It becomes: how much higher or lower that continent is relative to the intercept, which now **excludes** the other continent dummies in the model

--

This means that as the number of dummies increases, the number of continents in the intercept **decreases**


---


# More complicated categorical variables


Most of the variables we care about are not just dummies

--

They take on many values

--

E.g., education levels, sex, race, religion, etc.

--

What happens when we include one of these in a model? 

---


# Categorical variables = dummies

If you fit a model with a categorical variable, R will automatically break it up into n-1 dummies

```{r, echo = TRUE}
continent_model = lm(lifeExp ~ continent, data = gapminder)

tidy(continent_model)
```


---

# The same!

.pull-left[
```{r,echo = TRUE}
bigcat = lm(lifeExp ~ continent, 
   data = gapminder)
tidy(bigcat)
```
]

.pull-right[
```{r, echo = TRUE}
dummy_cat = lm(lifeExp ~ is_americas + is_europe + 
     is_asia + is_oceania,
   data = gap_dummies)
tidy(dummy_cat)
```
]


---

# Interpretation formula


```{r}
tribble(~Type, ~Approach, ~Intercept,
        "Continuous", "A one unit increase in X, SLOPE unit change in Y", "Average value of Y when X = 0",
        "Category", "The category is SLOPE units higher/lower than the intercept", "Average value of Y for baseline (missing) category") %>% 
  knitr::kable()
```


Interpreting coefficients is pretty confusing; it just requires practice


---


# We're on our way


We now know (sorta) how to interpret the coefficients on those big tables in the political science papers:

--

```{r}
knitr::include_graphics("images/reg-table.png")
```


---



# ðŸš¨ Your turn: number of kids ðŸš¨

--

1. Do happier people tend to have more or fewer kids than less happy people? Using the `gss_sm` dataset, regress `childs` (outcome) against `happy` (treatment). Interpret the output.

--

2. Which religions have the biggest families? Regress the number of siblings `sibs` (outcome) against respondent religion `relig`. Based on the output: which religion has the largest families, on average?

--

.small[
Hint: to figure out what values a categorical variable takes on, use the `distinct()` function, like so: `data %>% distinct(variable)`
]


```{r}
countdown::countdown(minutes = 10L)
```


