<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Causality</title>
    <meta charset="utf-8" />
    <meta name="author" content="Juan Tellez" />
    <meta name="date" content="2022-11-01" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <script type="application/json" id="xaringanExtra-editable-docid">{"id":"causal1","expires":14}</script>
    <script src="libs/himalaya/himalaya.js"></script>
    <script src="libs/js-cookie/js.cookie.js"></script>
    <link href="libs/editable/editable.css" rel="stylesheet" />
    <script src="libs/editable/editable.js"></script>
    <link href="libs/countdown/countdown.css" rel="stylesheet" />
    <script src="libs/countdown/countdown.js"></script>
    <link rel="stylesheet" href="css/my-theme.css" type="text/css" />
    <link rel="stylesheet" href="css/ath-inferno-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">










class: left, middle
background-image: url("images/dubois-spiral-2.png")
background-position: right
background-size: contain

# Causality

### *The Scientific Study of Politics*

### Professor Juan Tellez 

#### University of California, Davis

---


class: center
.large[
# Today's agenda
]

--
.box-1.large.sp-after[Why causality? And what is it?]

--
.box-2.large.sp-after[Fake data]

--
.box-3.large.sp-after[The problem with causality]

---

class: middle, center, inverse
# Why predict?
---


# Why predict


We don't know what's going to happen in the **future**

--

Or in places/cases where we don't have data

--

Even if in cases where we have data -- what's our *best guess*? 

--


We can use **models** to make decisions informed by patterns in the data


---


# Prediction is for making decisions


World Bank: what would happen to Jamaica if their GDP went up by 10k?

--

Who the hell knows, but we can use models to make an educated **guess**

--


&lt;img src="08-causality_files/figure-html/unnamed-chunk-1-1.png" width="90%" /&gt;

---


# Moving forward


.pull-left[
* There are lots of prediction resources online
* [Kaggle](http://kaggle.com) hosts prediction competitions with interesting data
* Give it a shot!
]


.pull-right[
&lt;img src="images/kaggle.png" width="100%" /&gt;
]


---

class: middle, center, inverse
# A turning point
---


# First half of course


.pull-left[
How to program, visualize data, modeling, relationships, etc.

Look at all the functions you learned:
&gt; `group_by`, `tally`, `summarise`, `filter`, `mutate`, `%&gt;%`, `distinct`, `lm`, `augment`, `tidy`, `ggplot`, `facet_wrap`...

There are thousands more!
]


.pull-right[
&lt;img src="images/learning-R.png" width="100%" /&gt;
]

---

# First half of course


Use models to estimate the relationship between X and Y:


```r
mod = lm(lifeExp ~ gdpPercap, data = gapminder)
tidy(mod)
```

```
## # A tibble: 2 √ó 5
##   term         estimate std.error statistic   p.value
##   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept) 54.0      0.315         171.  0        
## 2 gdpPercap    0.000765 0.0000258      29.7 3.57e-156
```

--

But is this relationship **causal**? Would an increase in GDP **cause** an increase in life expectancy, on average? 

---


# Second half of the course

.pull-left[

"How do we know if X **causes** y?"

Are our estimates **causal**? Academics fight about this all day!

This question is at center of **causal inference**

We will learn why it is so difficult to establish causality with data

We will also learn potential solutions

]


.pull-right[
&lt;div class="figure"&gt;
&lt;img src="images/the-thing.png" alt="Pictured: audience at a research presentation" width="100%" /&gt;
&lt;p class="caption"&gt;Pictured: audience at a research presentation&lt;/p&gt;
&lt;/div&gt;
]

---

class: center, middle, inverse
# Many interesting questions are causal

--

International relations: do peace-keepers **reduce conflict** in countries emerging from civil war? Does democracy make countries more **peaceful**?

--

Comparative politics: do elections reduce or increase **corruption**? Does repression increase or decrease **dissent**? 


--


American politics: do voter ID laws hurt general **turnout**? Do elites move **public opinion** or does public opinion move elites? 


---


# But not all


**Many** of the interesting questions people want to answer with data are causal

--

Some are not: 

Instagram might want to know: "Is there a person in this photo?"

But not care about what factors **cause** the picture to be a photo of a person

Depends on the question; most **why** questions are causal


---


# The value of causality


.pull-left[
One of our comparative advantages

Not just academic; companies, governments, NGOs also need to answer "why" questions

Does this policy work (or not)? Did it do what was intended? How effective or counterproductive was it? 
]

.pull-right[
&lt;img src="images/causal-job.png" width="100%" /&gt;
]

---


# What do we mean by causality?


.pull-left[
In this class, we say **X causes Y** if...

An **intervention** that changes the value of X produces a **probabilistic** change in Y

* .blue[Intervention] = X is being **changed** or altered

* .red[Probabilistic] = Y should change, *on average*, but need not in every instance

]

.pull-right[
&lt;img src="images/hume.jpeg" width="70%" /&gt;
]


---

# Interventions and probability


How do the two parts of our definition fit here?

&gt; Aspirin causes a reduction in fever symptoms

--

.blue[Intervention] = someone **takes** aspirin, we administer aspirin, we sneak it into someone's food, etc. 

--

.red[Probabilistic] = Taking aspirin doesn't work 100% of the time; but *in general*, *on average*, *more often than not*, etc., taking aspirin `\(\rightarrow\)` less fever

--

What about this example?

.can-edit.key-democracy[Instructions.]

???
Democratic institutions reduce the incidence of interstate war

---





# Terminology


We've seen this before:


|Variable |Meaning                                   |Examples                                    |
|:--------|:-----------------------------------------|:-------------------------------------------|
|Y        |The thing that is affected by a treatment |Employment, turnout, violence               |
|X        |The thing changing an outcome             |Min. wage laws, voter ID laws, peacekeepers |


---


class: center, middle, inverse
# The problem with causality
---

# Obviously causal relationships


A heavier car has to work harder to get from A to B

&lt;img src="08-causality_files/figure-html/unnamed-chunk-9-1.png" width="100%" /&gt;


---


# Obviously causal relationships


A bigger house is more desirable


&lt;img src="08-causality_files/figure-html/unnamed-chunk-10-1.png" width="100%" /&gt;


---


# Not obvious: education and earnings

.pull-left[
People who are already wealthy (or likely to become wealthy) get more education than people who are poor
]


.pull-right[
&lt;img src="images/education.png" width="100%" /&gt;
]



---


# Not obvious: voter ID and turnout

States that pass these laws are different from states that don't pass these laws

&lt;img src="images/vote-id.png" width="70%" /&gt;

---


# Spurious correlation


To make matters worse, correlation is common-place in nature:

--


&lt;img src="images/spurious-cheese.png" width="100%" /&gt;

---

class: middle, center, inverse
# The trouble with causality

--

We can't directly observe a change in X **causing** a change in Y

--

This is true even in **experiments**, where we directly manipulate stuff

--

All we can see are **correlations** between X and Y

--

Some of those correlations **are** causal; some **are not**; how can we tell?

---


# First step: yes, we can tell (sometimes)

--

Students are obsessed with *"correlation does not mean causation"*

But sometimes it does! that's the tricky part

&lt;img src="images/sponge-cause.jpeg" width="50%" style="display: block; margin: auto;" /&gt;


---


## Make up (simulate) data to convince ourselves


A good way to see that we correlation **can** equal causation is to make up (**simulate**) data where we know that X causes Y

--


We can make up data in R with the `rnorm()` function

--

`rnorm()` draws random numbers from a **normal distribution**

--

This means: the numbers it makes up are pretty close to some **mean**, plus or minus a **standard deviation**

--

&gt; rnorm(n = 100, mean = 10, sd = 2)

Generate 100 random numbers, most of which are +/- 2 away from 10

---


# Do winners keep winning?

--

Say we wanted to simulate data to show that doing well in .blue[elections] (treatment) **causes** increases in .red[campaign funding] (outcome). That is, that funders seek out winners

--

First step is generating the .blue[treatment variable] (performance in elections). 

--

Let's say 500 fake elections that are pretty close to 50 (a tie), plus or minus 5 points


---

# Faking (simulating) the treatment


We can use `tibble()` to make a data object and `rnorm()` to generate the variables

--

.blue[Treatment variable] 500 elections, vote share is 50% of the vote on average, +/- 5%

--

.scroll-output[

```r
*fake_election = tibble(party_share = rnorm(n = 500, mean = 50, sd = 5))
fake_election
```

```
## # A tibble: 500 √ó 1
##    party_share
##          &lt;dbl&gt;
##  1        47.5
##  2        58.8
##  3        50.9
##  4        50.3
##  5        48.0
##  6        54.0
##  7        46.5
##  8        49.5
##  9        41.4
## 10        46.5
## # ‚Ä¶ with 490 more rows
```
]

---

# And we can plot it


&lt;img src="08-causality_files/figure-html/unnamed-chunk-16-1.png" width="100%" /&gt;


---


# Making the outcome


Next we want to make up the .red[outcome] (how much each party raises in funding)

--

Let's say parties raise about 20k on average, plus or minus 4k

--

.scroll-output[

```r
fake_election = tibble(party_share = rnorm(n = 500, mean = 50, sd = 5), 
*                      funding = rnorm(n = 500, mean = 20000, sd = 4000))
fake_election
```

```
## # A tibble: 500 √ó 2
##    party_share funding
##          &lt;dbl&gt;   &lt;dbl&gt;
##  1        54.5  23515.
##  2        55.8  22406.
##  3        52.0  20658.
##  4        49.6  14602.
##  5        45.5  22900.
##  6        56.7  21524.
##  7        49.4  15449.
##  8        50.4  18854.
##  9        54.6  18177.
## 10        54.0  17170.
## # ‚Ä¶ with 490 more rows
```
]


---


# Making X cause Y

--

Now let's say we wanted to make it so that getting more votes **increased** campaign donations (winners attract funding)

--

Say for every percent of the vote a party gets, they get 2,000 (USD) more in donations `\(\rightarrow\)` this is the causal effect of .blue[vote share] on .red[donations]

--

We can do that in R like so: 

.scroll-output[

```r
fake_election = tibble(party_share = rnorm(n = 500, mean = 50, sd = 5), 
*                      funding = rnorm(n = 500, mean = 20000, sd = 4000) + 2000*party_share)
fake_election
```

```
## # A tibble: 500 √ó 2
##    party_share funding
##          &lt;dbl&gt;   &lt;dbl&gt;
##  1        50.6 120186.
##  2        48.6 116252.
##  3        46.7 113977.
##  4        45.4 111470.
##  5        51.8 127143.
##  6        50.1 119179.
##  7        50.2 123414.
##  8        52.5 131026.
##  9        45.4 103973.
## 10        57.3 133077.
## # ‚Ä¶ with 490 more rows
```
]


---

# Eyeballing it


Is our fake data convincing? We can plot it to see:

&lt;img src="08-causality_files/figure-html/unnamed-chunk-19-1.png" width="100%" /&gt;

---

# Can we get the causal estimate back?

We **know** the effect of vote share on campaign donations: it's 2k per percent of the vote

--

Can we use a model to get that estimate back?

--

Yes!


```r
lm(funding ~ party_share, data = fake_election) %&gt;% tidy()
```

```
## # A tibble: 2 √ó 5
##   term        estimate std.error statistic   p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)   19891.    1778.       11.2 4.55e- 26
## 2 party_share    1995.      35.4      56.4 2.11e-218
```


---


# Hope?

.pull-left[

* There are at least *some* scenarios where X causes Y, and 
    * This effect will be reflected in the data
    * And we can **estimate** the effect with a model
]

.pull-right[
&lt;img src="08-causality_files/figure-html/unnamed-chunk-21-1.png" width="100%" /&gt;
]

---

# üïµÔ∏è Your turn: Michael Lacour üïµÔ∏è

--

.pull-left[
* Lacour published a big study in *Science*
* Study showed talking to LGBT canvasser `\(\rightarrow\)` huge improvements in attitudes towards LGBT policy (gay marriage)
* Data was completely **fabricated**, using some of the same functions I showed you
]

.pull-right[
&lt;img src="images/lacour.png" width="100%" /&gt;
]


---

# üïµÔ∏è Your turn: Michael Lacour üïµÔ∏è


Using the steps I just went through above, make up some data that pre-confirms some pattern about the world you wish were true:

--
.small[
1. Change the .blue[treatment] and .red[outcome] variables in the code to ones of your choosing

2. Alter the parameters in `rnorm()` so the values make sense for your variables

3. Make a scatterplot with a trend line -- use `labs()` to help us make sense of the plot axes!
]

--

Some ideas: 


* Amount of alcohol consumption and your overall health
* Time spent studying for Prof. Tellez‚Äôs class and future income


<div class="countdown" id="timer_63618e81" style="right:0;bottom:0;font-size:1.5em;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">15</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>



---


class: middle, center, inverse
## So we (sometimes) *can* estimate causal effects
--

## Where does it all go wrong then? 
---

# An example from IR

Does democracy reduce international conflict?

Theory: war is costly and the costs are borne by citizens; countries where citizens have more input `\(\rightarrow\)` less conflict

--

X here is .blue[whether the country is a democracy] (versus autocracy)

Y is .red[the number of wars the country is involved in]

--

Ideal, imaginary approach: take a country, look at Y when democracy = 1, and then when democracy = 0


--

Do this for all countries, take the average

---


# Potential outcomes


This magical world where we can compare the number of wars when a country is a democracy versus when it is not is called the **potential outcomes**


|country | democracy| war|
|:-------|---------:|---:|
|Canada  |         0|   5|
|Canada  |         1|   4|
|China   |         0|   0|
|China   |         1|   1|
|USA     |         0|   1|
|USA     |         1|   0|



---


# The fundamental problem of causality


.pull-left[

In reality, we can only *observe* democracy at *one value* for each country

The US is a democracy, we can observe wars when democracy = 1, **but not when democracy = 0**

China is not a democracy, we can observe wars when democracy = 0, **but not when democracy = 1**
]

.pull-right[

|country | democracy| war|
|:-------|---------:|---:|
|Canada  |         0|   5|
|Canada  |         1|   4|
|China   |         0|   0|
|China   |         1|   1|
|USA     |         0|   1|
|USA     |         1|   0|

]

---


# Potential vs. observed


We only **observe** the world on the right, but not the left

.pull-left[

Table: Potential outcomes world

|country | democracy| war|
|:-------|---------:|---:|
|Canada  |         0|   5|
|Canada  |         1|   4|
|China   |         0|   0|
|China   |         1|   1|
|USA     |         0|   1|
|USA     |         1|   0|
]

.pull-left[

Table: Observed outcomes world

|country | democracy| war|
|:-------|---------:|---:|
|Canada  |         0|  NA|
|Canada  |         1|   4|
|China   |         0|   0|
|China   |         1|  NA|
|USA     |         0|  NA|
|USA     |         1|   0|
]


---


# The fundamental problem of causality

--

We have missing data on "what would have happened" had the US been an autocracy

--

"what would have happened" `\(\rightarrow\)` the **counterfactual**

--


Our goal in causal inference is to make as good a guess as possible as to what Y would have been had democracy = 0 instead of 1 (and vice versa)


---

# Comparing apples and oranges


Why not just compare the number of wars for countries where democracy = 0 (autocracies) versus the countries where democracy = 1 (democracies)?

--

If democracies fight less, then democracy **reduces** conflict

--


```r
observed %&gt;% 
  group_by(democracy) %&gt;% 
  summarise(wars = mean(war, na.rm = TRUE))
```

```
## # A tibble: 2 √ó 2
##   democracy  wars
##       &lt;dbl&gt; &lt;dbl&gt;
## 1         0     0
## 2         1     2
```

---


# Comparing apples and oranges


Implicitly, this means we are saying the countries that are *autocracies* are good **counterfactuals** for the countries that are democracies (and vice versa)

--

For instance, that China is a good counterfactual for the US

--

But China and the US are different in so many ways! They are not good **counterfactuals** of one another

--


We will see *exactly why* this is a problem in the following weeks

---

# Why experiments work

In an experiment, we *randomly* expose participants to some treatment, while others are exposed to nothing (or a placebo)

--


| Person|Shown an ad? | Democrats thermometer|
|------:|:------------|---------------------:|
|      1|Yes          |                  41.5|
|      2|No           |                 19.83|
|      3|Yes          |                 84.91|
|      4|No           |                 76.44|
|      5|No           |                 48.58|

--

We then compare the outcome of those who did and didn't get the treatment


---


# Why experiments work


Experiments have the same "problem" as the democracy and war example: we can't observe *the same person* seeing and not seeing the ad


| Person|Shown an ad? | Democrats thermometer|
|------:|:------------|---------------------:|
|      1|Yes          |                  41.5|
|      2|No           |                 19.83|


--

But since the experimental ad was *randomly* assigned, the people that did and didn't see the ad are good **counterfactuals** of one another

--

it is, **by definition**, just as likely a person who received treatment could have instead received the control/placebo (note how this differs from .blue[democracy] `\(\rightarrow\)` .red[war])


---

# The gold standard


This is why experiments are known as the **gold standard** of research

--

We have control over **treatment**, and we **randomize** it

--

With **observational data** that already exists in the world, we *don't* have control over treatment, and we *can't* randomize it

--

Experiments are great, but not feasible or ethical in most cases

--

So we'll have to take other measures to try to overcome these problems with observational data


---


# üß© Your turn: counterfactuals üß©


With neighbor, think through the counterfactual scenarios in these examples. What are the comparisons being made? And are they good counterfactuals? 

--

1. A study on whether international trade between two countries makes them more likely to form a defensive alliance.


2. A study on whether being a victim of a crime makes someone more supportive of authoritarian leaders


3. A study on whether those who served in the military are more likely to vote for "dovish" or "hawkish" candidates


<div class="countdown" id="timer_63618ea4" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">10</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLanguage": "r",
"highlightLines": true,
"highlightSpans": true,
"countIncrementalSlides": false,
"ratio": "16:9",
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
